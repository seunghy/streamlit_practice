2024-09-18 22:02:03,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:02:03,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:02:03,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:02:03,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:02:41,475:INFO:PyCaret ClassificationExperiment
2024-09-18 22:02:41,475:INFO:Logging name: clf-default-name
2024-09-18 22:02:41,475:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-18 22:02:41,475:INFO:version 3.3.2
2024-09-18 22:02:41,475:INFO:Initializing setup()
2024-09-18 22:02:41,475:INFO:self.USI: 59f3
2024-09-18 22:02:41,475:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'exp_id', 'is_multiclass', 'logging_param', '_ml_usecase', 'y_test', 'seed', 'gpu_param', 'fold_groups_param', 'pipeline', 'X_test', 'fold_shuffle_param', 'html_param', 'X', 'y', 'fold_generator', 'idx', 'data', 'n_jobs_param', 'y_train', '_available_plots', 'USI', 'memory', 'log_plots_param', 'X_train', 'fix_imbalance'}
2024-09-18 22:02:41,475:INFO:Checking environment
2024-09-18 22:02:41,475:INFO:python_version: 3.10.14
2024-09-18 22:02:41,475:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-09-18 22:02:41,475:INFO:machine: AMD64
2024-09-18 22:02:41,475:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-18 22:02:41,483:INFO:Memory: svmem(total=33968340992, available=20178219008, percent=40.6, used=13790121984, free=20178219008)
2024-09-18 22:02:41,483:INFO:Physical Core: 12
2024-09-18 22:02:41,483:INFO:Logical Core: 16
2024-09-18 22:02:41,483:INFO:Checking libraries
2024-09-18 22:02:41,483:INFO:System:
2024-09-18 22:02:41,483:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-09-18 22:02:41,483:INFO:executable: d:\Inferencing\practice_penguins\env_penguins\Scripts\python.exe
2024-09-18 22:02:41,483:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-18 22:02:41,483:INFO:PyCaret required dependencies:
2024-09-18 22:02:41,588:INFO:                 pip: 24.2
2024-09-18 22:02:41,588:INFO:          setuptools: 65.5.0
2024-09-18 22:02:41,588:INFO:             pycaret: 3.3.2
2024-09-18 22:02:41,588:INFO:             IPython: 8.27.0
2024-09-18 22:02:41,588:INFO:          ipywidgets: 8.1.5
2024-09-18 22:02:41,588:INFO:                tqdm: 4.66.5
2024-09-18 22:02:41,588:INFO:               numpy: 1.26.4
2024-09-18 22:02:41,588:INFO:              pandas: 2.1.4
2024-09-18 22:02:41,588:INFO:              jinja2: 3.1.4
2024-09-18 22:02:41,588:INFO:               scipy: 1.11.4
2024-09-18 22:02:41,588:INFO:              joblib: 1.3.2
2024-09-18 22:02:41,588:INFO:             sklearn: 1.4.2
2024-09-18 22:02:41,588:INFO:                pyod: 2.0.2
2024-09-18 22:02:41,588:INFO:            imblearn: 0.12.3
2024-09-18 22:02:41,588:INFO:   category_encoders: 2.6.3
2024-09-18 22:02:41,588:INFO:            lightgbm: 4.5.0
2024-09-18 22:02:41,588:INFO:               numba: 0.60.0
2024-09-18 22:02:41,588:INFO:            requests: 2.32.3
2024-09-18 22:02:41,588:INFO:          matplotlib: 3.7.5
2024-09-18 22:02:41,588:INFO:          scikitplot: 0.3.7
2024-09-18 22:02:41,588:INFO:         yellowbrick: 1.5
2024-09-18 22:02:41,588:INFO:              plotly: 5.24.1
2024-09-18 22:02:41,588:INFO:    plotly-resampler: Not installed
2024-09-18 22:02:41,588:INFO:             kaleido: 0.2.1
2024-09-18 22:02:41,588:INFO:           schemdraw: 0.15
2024-09-18 22:02:41,588:INFO:         statsmodels: 0.14.3
2024-09-18 22:02:41,588:INFO:              sktime: 0.26.0
2024-09-18 22:02:41,588:INFO:               tbats: 1.1.3
2024-09-18 22:02:41,588:INFO:            pmdarima: 2.0.4
2024-09-18 22:02:41,588:INFO:              psutil: 6.0.0
2024-09-18 22:02:41,588:INFO:          markupsafe: 2.1.5
2024-09-18 22:02:41,588:INFO:             pickle5: Not installed
2024-09-18 22:02:41,588:INFO:         cloudpickle: 3.0.0
2024-09-18 22:02:41,588:INFO:         deprecation: 2.1.0
2024-09-18 22:02:41,588:INFO:              xxhash: 3.5.0
2024-09-18 22:02:41,588:INFO:           wurlitzer: Not installed
2024-09-18 22:02:41,588:INFO:PyCaret optional dependencies:
2024-09-18 22:02:41,612:INFO:                shap: Not installed
2024-09-18 22:02:41,612:INFO:           interpret: Not installed
2024-09-18 22:02:41,612:INFO:                umap: Not installed
2024-09-18 22:02:41,612:INFO:     ydata_profiling: Not installed
2024-09-18 22:02:41,612:INFO:  explainerdashboard: Not installed
2024-09-18 22:02:41,612:INFO:             autoviz: Not installed
2024-09-18 22:02:41,612:INFO:           fairlearn: Not installed
2024-09-18 22:02:41,612:INFO:          deepchecks: Not installed
2024-09-18 22:02:41,612:INFO:             xgboost: Installed but version unavailable
2024-09-18 22:02:41,612:INFO:            catboost: Not installed
2024-09-18 22:02:41,612:INFO:              kmodes: Not installed
2024-09-18 22:02:41,612:INFO:             mlxtend: Not installed
2024-09-18 22:02:41,612:INFO:       statsforecast: Not installed
2024-09-18 22:02:41,612:INFO:        tune_sklearn: Not installed
2024-09-18 22:02:41,612:INFO:                 ray: Not installed
2024-09-18 22:02:41,612:INFO:            hyperopt: Not installed
2024-09-18 22:02:41,612:INFO:              optuna: Not installed
2024-09-18 22:02:41,612:INFO:               skopt: Not installed
2024-09-18 22:02:41,612:INFO:              mlflow: Not installed
2024-09-18 22:02:41,612:INFO:              gradio: Not installed
2024-09-18 22:02:41,612:INFO:             fastapi: Not installed
2024-09-18 22:02:41,612:INFO:             uvicorn: Not installed
2024-09-18 22:02:41,612:INFO:              m2cgen: Not installed
2024-09-18 22:02:41,612:INFO:           evidently: Not installed
2024-09-18 22:02:41,612:INFO:               fugue: Not installed
2024-09-18 22:02:41,612:INFO:           streamlit: Not installed
2024-09-18 22:02:41,612:INFO:             prophet: Not installed
2024-09-18 22:02:41,612:INFO:None
2024-09-18 22:02:41,612:INFO:Set up data.
2024-09-18 22:02:41,612:INFO:Set up folding strategy.
2024-09-18 22:02:41,612:INFO:Set up train/test split.
2024-09-18 22:02:41,628:INFO:Set up index.
2024-09-18 22:02:41,628:INFO:Assigning column types.
2024-09-18 22:02:41,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-18 22:02:41,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-18 22:02:41,660:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:02:41,694:INFO:Soft dependency imported: xgboost: None
2024-09-18 22:03:18,915:INFO:PyCaret ClassificationExperiment
2024-09-18 22:03:18,915:INFO:Logging name: clf-default-name
2024-09-18 22:03:18,916:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-18 22:03:18,916:INFO:version 3.3.2
2024-09-18 22:03:18,916:INFO:Initializing setup()
2024-09-18 22:03:18,917:INFO:self.USI: 1800
2024-09-18 22:03:18,917:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'exp_id', 'is_multiclass', 'logging_param', '_ml_usecase', 'y_test', 'seed', 'gpu_param', 'fold_groups_param', 'pipeline', 'X_test', 'fold_shuffle_param', 'html_param', 'X', 'y', 'fold_generator', 'idx', 'data', 'n_jobs_param', 'y_train', '_available_plots', 'USI', 'memory', 'log_plots_param', 'X_train', 'fix_imbalance'}
2024-09-18 22:03:18,917:INFO:Checking environment
2024-09-18 22:03:18,917:INFO:python_version: 3.10.14
2024-09-18 22:03:18,917:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-09-18 22:03:18,917:INFO:machine: AMD64
2024-09-18 22:03:18,917:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-18 22:03:18,926:INFO:Memory: svmem(total=33968340992, available=19947790336, percent=41.3, used=14020550656, free=19947790336)
2024-09-18 22:03:18,926:INFO:Physical Core: 12
2024-09-18 22:03:18,926:INFO:Logical Core: 16
2024-09-18 22:03:18,926:INFO:Checking libraries
2024-09-18 22:03:18,926:INFO:System:
2024-09-18 22:03:18,926:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-09-18 22:03:18,926:INFO:executable: d:\Inferencing\practice_penguins\env_penguins\Scripts\python.exe
2024-09-18 22:03:18,926:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-18 22:03:18,926:INFO:PyCaret required dependencies:
2024-09-18 22:03:18,926:INFO:                 pip: 24.2
2024-09-18 22:03:18,926:INFO:          setuptools: 65.5.0
2024-09-18 22:03:18,926:INFO:             pycaret: 3.3.2
2024-09-18 22:03:18,926:INFO:             IPython: 8.27.0
2024-09-18 22:03:18,926:INFO:          ipywidgets: 8.1.5
2024-09-18 22:03:18,926:INFO:                tqdm: 4.66.5
2024-09-18 22:03:18,926:INFO:               numpy: 1.26.4
2024-09-18 22:03:18,926:INFO:              pandas: 2.1.4
2024-09-18 22:03:18,926:INFO:              jinja2: 3.1.4
2024-09-18 22:03:18,926:INFO:               scipy: 1.11.4
2024-09-18 22:03:18,926:INFO:              joblib: 1.3.2
2024-09-18 22:03:18,926:INFO:             sklearn: 1.4.2
2024-09-18 22:03:18,926:INFO:                pyod: 2.0.2
2024-09-18 22:03:18,926:INFO:            imblearn: 0.12.3
2024-09-18 22:03:18,926:INFO:   category_encoders: 2.6.3
2024-09-18 22:03:18,926:INFO:            lightgbm: 4.5.0
2024-09-18 22:03:18,926:INFO:               numba: 0.60.0
2024-09-18 22:03:18,926:INFO:            requests: 2.32.3
2024-09-18 22:03:18,926:INFO:          matplotlib: 3.7.5
2024-09-18 22:03:18,926:INFO:          scikitplot: 0.3.7
2024-09-18 22:03:18,926:INFO:         yellowbrick: 1.5
2024-09-18 22:03:18,926:INFO:              plotly: 5.24.1
2024-09-18 22:03:18,926:INFO:    plotly-resampler: Not installed
2024-09-18 22:03:18,926:INFO:             kaleido: 0.2.1
2024-09-18 22:03:18,926:INFO:           schemdraw: 0.15
2024-09-18 22:03:18,926:INFO:         statsmodels: 0.14.3
2024-09-18 22:03:18,926:INFO:              sktime: 0.26.0
2024-09-18 22:03:18,926:INFO:               tbats: 1.1.3
2024-09-18 22:03:18,926:INFO:            pmdarima: 2.0.4
2024-09-18 22:03:18,926:INFO:              psutil: 6.0.0
2024-09-18 22:03:18,926:INFO:          markupsafe: 2.1.5
2024-09-18 22:03:18,926:INFO:             pickle5: Not installed
2024-09-18 22:03:18,926:INFO:         cloudpickle: 3.0.0
2024-09-18 22:03:18,926:INFO:         deprecation: 2.1.0
2024-09-18 22:03:18,926:INFO:              xxhash: 3.5.0
2024-09-18 22:03:18,926:INFO:           wurlitzer: Not installed
2024-09-18 22:03:18,926:INFO:PyCaret optional dependencies:
2024-09-18 22:03:18,926:INFO:                shap: Not installed
2024-09-18 22:03:18,926:INFO:           interpret: Not installed
2024-09-18 22:03:18,926:INFO:                umap: Not installed
2024-09-18 22:03:18,926:INFO:     ydata_profiling: Not installed
2024-09-18 22:03:18,926:INFO:  explainerdashboard: Not installed
2024-09-18 22:03:18,926:INFO:             autoviz: Not installed
2024-09-18 22:03:18,926:INFO:           fairlearn: Not installed
2024-09-18 22:03:18,926:INFO:          deepchecks: Not installed
2024-09-18 22:03:18,926:INFO:             xgboost: Installed but version unavailable
2024-09-18 22:03:18,926:INFO:            catboost: Not installed
2024-09-18 22:03:18,926:INFO:              kmodes: Not installed
2024-09-18 22:03:18,934:INFO:             mlxtend: Not installed
2024-09-18 22:03:18,934:INFO:       statsforecast: Not installed
2024-09-18 22:03:18,934:INFO:        tune_sklearn: Not installed
2024-09-18 22:03:18,934:INFO:                 ray: Not installed
2024-09-18 22:03:18,934:INFO:            hyperopt: Not installed
2024-09-18 22:03:18,934:INFO:              optuna: Not installed
2024-09-18 22:03:18,934:INFO:               skopt: Not installed
2024-09-18 22:03:18,934:INFO:              mlflow: Not installed
2024-09-18 22:03:18,934:INFO:              gradio: Not installed
2024-09-18 22:03:18,934:INFO:             fastapi: Not installed
2024-09-18 22:03:18,934:INFO:             uvicorn: Not installed
2024-09-18 22:03:18,934:INFO:              m2cgen: Not installed
2024-09-18 22:03:18,934:INFO:           evidently: Not installed
2024-09-18 22:03:18,934:INFO:               fugue: Not installed
2024-09-18 22:03:18,934:INFO:           streamlit: Not installed
2024-09-18 22:03:18,934:INFO:             prophet: Not installed
2024-09-18 22:03:18,934:INFO:None
2024-09-18 22:03:18,934:INFO:Set up data.
2024-09-18 22:03:18,942:INFO:Set up folding strategy.
2024-09-18 22:03:18,942:INFO:Set up train/test split.
2024-09-18 22:03:18,950:INFO:Set up index.
2024-09-18 22:03:18,950:INFO:Assigning column types.
2024-09-18 22:03:18,966:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-18 22:03:19,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-18 22:03:19,048:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:03:19,064:INFO:Soft dependency imported: xgboost: None
2024-09-18 22:03:35,822:INFO:PyCaret ClassificationExperiment
2024-09-18 22:03:35,822:INFO:Logging name: clf-default-name
2024-09-18 22:03:35,823:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-18 22:03:35,823:INFO:version 3.3.2
2024-09-18 22:03:35,823:INFO:Initializing setup()
2024-09-18 22:03:35,823:INFO:self.USI: 5e80
2024-09-18 22:03:35,823:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'target_param', 'exp_id', 'is_multiclass', 'logging_param', '_ml_usecase', 'y_test', 'seed', 'gpu_param', 'fold_groups_param', 'pipeline', 'X_test', 'fold_shuffle_param', 'html_param', 'X', 'y', 'fold_generator', 'idx', 'data', 'n_jobs_param', 'y_train', '_available_plots', 'USI', 'memory', 'log_plots_param', 'X_train', 'fix_imbalance'}
2024-09-18 22:03:35,823:INFO:Checking environment
2024-09-18 22:03:35,823:INFO:python_version: 3.10.14
2024-09-18 22:03:35,823:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-09-18 22:03:35,824:INFO:machine: AMD64
2024-09-18 22:03:35,824:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-18 22:03:35,829:INFO:Memory: svmem(total=33968340992, available=20001677312, percent=41.1, used=13966663680, free=20001677312)
2024-09-18 22:03:35,829:INFO:Physical Core: 12
2024-09-18 22:03:35,829:INFO:Logical Core: 16
2024-09-18 22:03:35,829:INFO:Checking libraries
2024-09-18 22:03:35,829:INFO:System:
2024-09-18 22:03:35,829:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-09-18 22:03:35,829:INFO:executable: d:\Inferencing\practice_penguins\env_penguins\Scripts\python.exe
2024-09-18 22:03:35,829:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-18 22:03:35,829:INFO:PyCaret required dependencies:
2024-09-18 22:03:35,829:INFO:                 pip: 24.2
2024-09-18 22:03:35,829:INFO:          setuptools: 65.5.0
2024-09-18 22:03:35,829:INFO:             pycaret: 3.3.2
2024-09-18 22:03:35,829:INFO:             IPython: 8.27.0
2024-09-18 22:03:35,829:INFO:          ipywidgets: 8.1.5
2024-09-18 22:03:35,829:INFO:                tqdm: 4.66.5
2024-09-18 22:03:35,829:INFO:               numpy: 1.26.4
2024-09-18 22:03:35,829:INFO:              pandas: 2.1.4
2024-09-18 22:03:35,829:INFO:              jinja2: 3.1.4
2024-09-18 22:03:35,829:INFO:               scipy: 1.11.4
2024-09-18 22:03:35,829:INFO:              joblib: 1.3.2
2024-09-18 22:03:35,829:INFO:             sklearn: 1.4.2
2024-09-18 22:03:35,829:INFO:                pyod: 2.0.2
2024-09-18 22:03:35,829:INFO:            imblearn: 0.12.3
2024-09-18 22:03:35,829:INFO:   category_encoders: 2.6.3
2024-09-18 22:03:35,829:INFO:            lightgbm: 4.5.0
2024-09-18 22:03:35,829:INFO:               numba: 0.60.0
2024-09-18 22:03:35,829:INFO:            requests: 2.32.3
2024-09-18 22:03:35,829:INFO:          matplotlib: 3.7.5
2024-09-18 22:03:35,837:INFO:          scikitplot: 0.3.7
2024-09-18 22:03:35,837:INFO:         yellowbrick: 1.5
2024-09-18 22:03:35,837:INFO:              plotly: 5.24.1
2024-09-18 22:03:35,837:INFO:    plotly-resampler: Not installed
2024-09-18 22:03:35,837:INFO:             kaleido: 0.2.1
2024-09-18 22:03:35,837:INFO:           schemdraw: 0.15
2024-09-18 22:03:35,837:INFO:         statsmodels: 0.14.3
2024-09-18 22:03:35,837:INFO:              sktime: 0.26.0
2024-09-18 22:03:35,837:INFO:               tbats: 1.1.3
2024-09-18 22:03:35,837:INFO:            pmdarima: 2.0.4
2024-09-18 22:03:35,837:INFO:              psutil: 6.0.0
2024-09-18 22:03:35,837:INFO:          markupsafe: 2.1.5
2024-09-18 22:03:35,837:INFO:             pickle5: Not installed
2024-09-18 22:03:35,837:INFO:         cloudpickle: 3.0.0
2024-09-18 22:03:35,837:INFO:         deprecation: 2.1.0
2024-09-18 22:03:35,837:INFO:              xxhash: 3.5.0
2024-09-18 22:03:35,837:INFO:           wurlitzer: Not installed
2024-09-18 22:03:35,837:INFO:PyCaret optional dependencies:
2024-09-18 22:03:35,837:INFO:                shap: Not installed
2024-09-18 22:03:35,837:INFO:           interpret: Not installed
2024-09-18 22:03:35,837:INFO:                umap: Not installed
2024-09-18 22:03:35,837:INFO:     ydata_profiling: Not installed
2024-09-18 22:03:35,837:INFO:  explainerdashboard: Not installed
2024-09-18 22:03:35,837:INFO:             autoviz: Not installed
2024-09-18 22:03:35,837:INFO:           fairlearn: Not installed
2024-09-18 22:03:35,837:INFO:          deepchecks: Not installed
2024-09-18 22:03:35,837:INFO:             xgboost: Installed but version unavailable
2024-09-18 22:03:35,837:INFO:            catboost: Not installed
2024-09-18 22:03:35,837:INFO:              kmodes: Not installed
2024-09-18 22:03:35,837:INFO:             mlxtend: Not installed
2024-09-18 22:03:35,837:INFO:       statsforecast: Not installed
2024-09-18 22:03:35,837:INFO:        tune_sklearn: Not installed
2024-09-18 22:03:35,845:INFO:                 ray: Not installed
2024-09-18 22:03:35,845:INFO:            hyperopt: Not installed
2024-09-18 22:03:35,845:INFO:              optuna: Not installed
2024-09-18 22:03:35,845:INFO:               skopt: Not installed
2024-09-18 22:03:35,845:INFO:              mlflow: Not installed
2024-09-18 22:03:35,845:INFO:              gradio: Not installed
2024-09-18 22:03:35,845:INFO:             fastapi: Not installed
2024-09-18 22:03:35,845:INFO:             uvicorn: Not installed
2024-09-18 22:03:35,845:INFO:              m2cgen: Not installed
2024-09-18 22:03:35,845:INFO:           evidently: Not installed
2024-09-18 22:03:35,845:INFO:               fugue: Not installed
2024-09-18 22:03:35,845:INFO:           streamlit: Not installed
2024-09-18 22:03:35,845:INFO:             prophet: Not installed
2024-09-18 22:03:35,845:INFO:None
2024-09-18 22:03:35,845:INFO:Set up data.
2024-09-18 22:03:35,861:INFO:Set up folding strategy.
2024-09-18 22:03:35,861:INFO:Set up train/test split.
2024-09-18 22:03:35,869:INFO:Set up index.
2024-09-18 22:03:35,869:INFO:Assigning column types.
2024-09-18 22:03:35,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-18 22:03:36,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-18 22:03:36,072:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:03:36,189:INFO:Soft dependency imported: xgboost: None
2024-09-18 22:04:01,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:01,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:01,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:01,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:04,189:INFO:PyCaret ClassificationExperiment
2024-09-18 22:04:04,190:INFO:Logging name: clf-default-name
2024-09-18 22:04:04,190:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-18 22:04:04,191:INFO:version 3.3.2
2024-09-18 22:04:04,191:INFO:Initializing setup()
2024-09-18 22:04:04,191:INFO:self.USI: f517
2024-09-18 22:04:04,192:INFO:self._variable_keys: {'fold_shuffle_param', '_available_plots', 'log_plots_param', 'X', 'pipeline', 'gpu_param', 'n_jobs_param', 'data', 'y', 'target_param', 'seed', 'idx', '_ml_usecase', 'is_multiclass', 'html_param', 'y_test', 'USI', 'fix_imbalance', 'fold_groups_param', 'logging_param', 'y_train', 'gpu_n_jobs_param', 'X_train', 'memory', 'X_test', 'exp_name_log', 'exp_id', 'fold_generator'}
2024-09-18 22:04:04,193:INFO:Checking environment
2024-09-18 22:04:04,193:INFO:python_version: 3.10.14
2024-09-18 22:04:04,193:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-09-18 22:04:04,193:INFO:machine: AMD64
2024-09-18 22:04:04,193:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-18 22:04:04,195:INFO:Memory: svmem(total=33968340992, available=19998720000, percent=41.1, used=13969620992, free=19998720000)
2024-09-18 22:04:04,203:INFO:Physical Core: 12
2024-09-18 22:04:04,203:INFO:Logical Core: 16
2024-09-18 22:04:04,203:INFO:Checking libraries
2024-09-18 22:04:04,203:INFO:System:
2024-09-18 22:04:04,203:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-09-18 22:04:04,203:INFO:executable: d:\Inferencing\practice_penguins\env_penguins\Scripts\python.exe
2024-09-18 22:04:04,203:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-18 22:04:04,203:INFO:PyCaret required dependencies:
2024-09-18 22:04:04,333:INFO:                 pip: 24.2
2024-09-18 22:04:04,333:INFO:          setuptools: 65.5.0
2024-09-18 22:04:04,333:INFO:             pycaret: 3.3.2
2024-09-18 22:04:04,333:INFO:             IPython: 8.27.0
2024-09-18 22:04:04,333:INFO:          ipywidgets: 8.1.5
2024-09-18 22:04:04,333:INFO:                tqdm: 4.66.5
2024-09-18 22:04:04,333:INFO:               numpy: 1.26.4
2024-09-18 22:04:04,333:INFO:              pandas: 2.1.4
2024-09-18 22:04:04,333:INFO:              jinja2: 3.1.4
2024-09-18 22:04:04,333:INFO:               scipy: 1.11.4
2024-09-18 22:04:04,333:INFO:              joblib: 1.3.2
2024-09-18 22:04:04,333:INFO:             sklearn: 1.4.2
2024-09-18 22:04:04,333:INFO:                pyod: 2.0.2
2024-09-18 22:04:04,333:INFO:            imblearn: 0.12.3
2024-09-18 22:04:04,333:INFO:   category_encoders: 2.6.3
2024-09-18 22:04:04,333:INFO:            lightgbm: 4.5.0
2024-09-18 22:04:04,333:INFO:               numba: 0.60.0
2024-09-18 22:04:04,333:INFO:            requests: 2.32.3
2024-09-18 22:04:04,333:INFO:          matplotlib: 3.7.5
2024-09-18 22:04:04,333:INFO:          scikitplot: 0.3.7
2024-09-18 22:04:04,333:INFO:         yellowbrick: 1.5
2024-09-18 22:04:04,341:INFO:              plotly: 5.24.1
2024-09-18 22:04:04,341:INFO:    plotly-resampler: Not installed
2024-09-18 22:04:04,341:INFO:             kaleido: 0.2.1
2024-09-18 22:04:04,341:INFO:           schemdraw: 0.15
2024-09-18 22:04:04,341:INFO:         statsmodels: 0.14.3
2024-09-18 22:04:04,341:INFO:              sktime: 0.26.0
2024-09-18 22:04:04,341:INFO:               tbats: 1.1.3
2024-09-18 22:04:04,341:INFO:            pmdarima: 2.0.4
2024-09-18 22:04:04,341:INFO:              psutil: 6.0.0
2024-09-18 22:04:04,341:INFO:          markupsafe: 2.1.5
2024-09-18 22:04:04,341:INFO:             pickle5: Not installed
2024-09-18 22:04:04,341:INFO:         cloudpickle: 3.0.0
2024-09-18 22:04:04,341:INFO:         deprecation: 2.1.0
2024-09-18 22:04:04,341:INFO:              xxhash: 3.5.0
2024-09-18 22:04:04,341:INFO:           wurlitzer: Not installed
2024-09-18 22:04:04,341:INFO:PyCaret optional dependencies:
2024-09-18 22:04:04,434:INFO:                shap: Not installed
2024-09-18 22:04:04,434:INFO:           interpret: Not installed
2024-09-18 22:04:04,434:INFO:                umap: Not installed
2024-09-18 22:04:04,434:INFO:     ydata_profiling: Not installed
2024-09-18 22:04:04,434:INFO:  explainerdashboard: Not installed
2024-09-18 22:04:04,434:INFO:             autoviz: Not installed
2024-09-18 22:04:04,442:INFO:           fairlearn: Not installed
2024-09-18 22:04:04,442:INFO:          deepchecks: Not installed
2024-09-18 22:04:04,443:INFO:             xgboost: 2.1.1
2024-09-18 22:04:04,443:INFO:            catboost: Not installed
2024-09-18 22:04:04,443:INFO:              kmodes: Not installed
2024-09-18 22:04:04,443:INFO:             mlxtend: Not installed
2024-09-18 22:04:04,443:INFO:       statsforecast: Not installed
2024-09-18 22:04:04,443:INFO:        tune_sklearn: Not installed
2024-09-18 22:04:04,443:INFO:                 ray: Not installed
2024-09-18 22:04:04,443:INFO:            hyperopt: Not installed
2024-09-18 22:04:04,443:INFO:              optuna: Not installed
2024-09-18 22:04:04,443:INFO:               skopt: Not installed
2024-09-18 22:04:04,443:INFO:              mlflow: Not installed
2024-09-18 22:04:04,443:INFO:              gradio: Not installed
2024-09-18 22:04:04,443:INFO:             fastapi: Not installed
2024-09-18 22:04:04,443:INFO:             uvicorn: Not installed
2024-09-18 22:04:04,443:INFO:              m2cgen: Not installed
2024-09-18 22:04:04,443:INFO:           evidently: Not installed
2024-09-18 22:04:04,443:INFO:               fugue: Not installed
2024-09-18 22:04:04,443:INFO:           streamlit: Not installed
2024-09-18 22:04:04,443:INFO:             prophet: Not installed
2024-09-18 22:04:04,443:INFO:None
2024-09-18 22:04:04,443:INFO:Set up data.
2024-09-18 22:04:04,451:INFO:Set up folding strategy.
2024-09-18 22:04:04,451:INFO:Set up train/test split.
2024-09-18 22:04:04,493:INFO:Set up index.
2024-09-18 22:04:04,493:INFO:Assigning column types.
2024-09-18 22:04:04,500:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-18 22:04:04,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-18 22:04:04,651:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:04:04,684:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:04,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:04,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-18 22:04:04,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:04:04,734:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:04,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:04,734:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-18 22:04:04,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:04:04,784:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:04,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:04,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-18 22:04:04,834:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:04,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:04,834:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-18 22:04:04,884:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:04,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:04,926:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:04,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:04,934:INFO:Preparing preprocessing pipeline...
2024-09-18 22:04:04,934:INFO:Set up label encoding.
2024-09-18 22:04:04,942:INFO:Set up simple imputation.
2024-09-18 22:04:04,943:INFO:Set up encoding of ordinal features.
2024-09-18 22:04:04,943:INFO:Set up encoding of categorical features.
2024-09-18 22:04:05,008:INFO:Finished creating preprocessing pipeline.
2024-09-18 22:04:05,018:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\10188\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['culmen_length_mm',
                                             'culmen_depth_mm',
                                             'flipper_length_mm',
                                             'body_mass_g'],
                                    transformer=SimpleImputer(ad...
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': FEMALE    0
MALE      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['island'],
                                    transformer=OneHotEncoder(cols=['island'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-09-18 22:04:05,018:INFO:Creating final display dataframe.
2024-09-18 22:04:05,167:INFO:Setup _display_container:                     Description                               Value
0                    Session id                                 123
1                        Target                             species
2                   Target type                          Multiclass
3                Target mapping  Adelie: 0, Chinstrap: 1, Gentoo: 2
4           Original data shape                            (333, 7)
5        Transformed data shape                            (333, 9)
6   Transformed train set shape                            (233, 9)
7    Transformed test set shape                            (100, 9)
8              Numeric features                                   4
9          Categorical features                                   2
10                   Preprocess                                True
11              Imputation type                              simple
12           Numeric imputation                                mean
13       Categorical imputation                                mode
14     Maximum one-hot encoding                                  25
15              Encoding method                                None
16               Fold Generator                     StratifiedKFold
17                  Fold Number                                  10
18                     CPU Jobs                                  -1
19                      Use GPU                               False
20               Log Experiment                               False
21              Experiment Name                    clf-default-name
22                          USI                                f517
2024-09-18 22:04:05,241:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:05,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:05,302:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-18 22:04:05,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-18 22:04:05,302:INFO:setup() successfully completed in 1.13s...............
2024-09-18 22:04:05,977:INFO:Initializing compare_models()
2024-09-18 22:04:05,985:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-18 22:04:05,985:INFO:Checking exceptions
2024-09-18 22:04:05,994:INFO:Preparing display monitor
2024-09-18 22:04:06,066:INFO:Initializing Logistic Regression
2024-09-18 22:04:06,066:INFO:Total runtime is 0.0 minutes
2024-09-18 22:04:06,074:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:06,074:INFO:Initializing create_model()
2024-09-18 22:04:06,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:06,074:INFO:Checking exceptions
2024-09-18 22:04:06,074:INFO:Importing libraries
2024-09-18 22:04:06,074:INFO:Copying training dataset
2024-09-18 22:04:06,090:INFO:Defining folds
2024-09-18 22:04:06,090:INFO:Declaring metric variables
2024-09-18 22:04:06,098:INFO:Importing untrained model
2024-09-18 22:04:06,114:INFO:Logistic Regression Imported successfully
2024-09-18 22:04:06,130:INFO:Starting cross validation
2024-09-18 22:04:06,138:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:14,291:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,315:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,323:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,323:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,323:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,436:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,460:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,468:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,468:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,468:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,660:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,684:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,692:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,692:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,700:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,700:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,708:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,708:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,716:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,716:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,874:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,874:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,890:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,890:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,898:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,898:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,898:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,906:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,906:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,906:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,914:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,930:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,930:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:14,930:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,938:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,938:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,962:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:14,970:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,970:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,970:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:14,978:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:15,002:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:15,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-18 22:04:15,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,036:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:15,036:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,036:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,036:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,060:INFO:Calculating mean and std
2024-09-18 22:04:15,060:INFO:Creating metrics dataframe
2024-09-18 22:04:15,060:INFO:Uploading results into container
2024-09-18 22:04:15,060:INFO:Uploading model into container now
2024-09-18 22:04:15,060:INFO:_master_model_container: 1
2024-09-18 22:04:15,060:INFO:_display_container: 2
2024-09-18 22:04:15,060:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-18 22:04:15,060:INFO:create_model() successfully completed......................................
2024-09-18 22:04:15,124:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:15,124:INFO:Creating metrics dataframe
2024-09-18 22:04:15,132:INFO:Initializing K Neighbors Classifier
2024-09-18 22:04:15,132:INFO:Total runtime is 0.15109978914260863 minutes
2024-09-18 22:04:15,132:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:15,132:INFO:Initializing create_model()
2024-09-18 22:04:15,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:15,132:INFO:Checking exceptions
2024-09-18 22:04:15,132:INFO:Importing libraries
2024-09-18 22:04:15,132:INFO:Copying training dataset
2024-09-18 22:04:15,140:INFO:Defining folds
2024-09-18 22:04:15,140:INFO:Declaring metric variables
2024-09-18 22:04:15,140:INFO:Importing untrained model
2024-09-18 22:04:15,148:INFO:K Neighbors Classifier Imported successfully
2024-09-18 22:04:15,148:INFO:Starting cross validation
2024-09-18 22:04:15,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:15,319:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,319:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,343:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,343:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,343:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,351:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:15,351:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:19,918:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:19,927:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:19,927:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,184:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,192:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,192:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,200:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,208:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,208:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,208:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,216:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,216:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,296:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,304:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,304:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,460:INFO:Calculating mean and std
2024-09-18 22:04:20,460:INFO:Creating metrics dataframe
2024-09-18 22:04:20,460:INFO:Uploading results into container
2024-09-18 22:04:20,460:INFO:Uploading model into container now
2024-09-18 22:04:20,460:INFO:_master_model_container: 2
2024-09-18 22:04:20,460:INFO:_display_container: 2
2024-09-18 22:04:20,460:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-18 22:04:20,460:INFO:create_model() successfully completed......................................
2024-09-18 22:04:20,524:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:20,524:INFO:Creating metrics dataframe
2024-09-18 22:04:20,532:INFO:Initializing Naive Bayes
2024-09-18 22:04:20,532:INFO:Total runtime is 0.24110132853190103 minutes
2024-09-18 22:04:20,532:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:20,532:INFO:Initializing create_model()
2024-09-18 22:04:20,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:20,532:INFO:Checking exceptions
2024-09-18 22:04:20,532:INFO:Importing libraries
2024-09-18 22:04:20,532:INFO:Copying training dataset
2024-09-18 22:04:20,532:INFO:Defining folds
2024-09-18 22:04:20,532:INFO:Declaring metric variables
2024-09-18 22:04:20,540:INFO:Importing untrained model
2024-09-18 22:04:20,540:INFO:Naive Bayes Imported successfully
2024-09-18 22:04:20,548:INFO:Starting cross validation
2024-09-18 22:04:20,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:20,632:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,632:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,632:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,640:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,640:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,640:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,664:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,672:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,696:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,696:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,696:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,696:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,696:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,696:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,704:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,704:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,704:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,720:INFO:Calculating mean and std
2024-09-18 22:04:20,720:INFO:Creating metrics dataframe
2024-09-18 22:04:20,720:INFO:Uploading results into container
2024-09-18 22:04:20,720:INFO:Uploading model into container now
2024-09-18 22:04:20,720:INFO:_master_model_container: 3
2024-09-18 22:04:20,720:INFO:_display_container: 2
2024-09-18 22:04:20,720:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-18 22:04:20,720:INFO:create_model() successfully completed......................................
2024-09-18 22:04:20,777:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:20,777:INFO:Creating metrics dataframe
2024-09-18 22:04:20,785:INFO:Initializing Decision Tree Classifier
2024-09-18 22:04:20,785:INFO:Total runtime is 0.24532025655110676 minutes
2024-09-18 22:04:20,785:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:20,793:INFO:Initializing create_model()
2024-09-18 22:04:20,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:20,793:INFO:Checking exceptions
2024-09-18 22:04:20,793:INFO:Importing libraries
2024-09-18 22:04:20,793:INFO:Copying training dataset
2024-09-18 22:04:20,794:INFO:Defining folds
2024-09-18 22:04:20,794:INFO:Declaring metric variables
2024-09-18 22:04:20,794:INFO:Importing untrained model
2024-09-18 22:04:20,802:INFO:Decision Tree Classifier Imported successfully
2024-09-18 22:04:20,810:INFO:Starting cross validation
2024-09-18 22:04:20,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:20,911:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,911:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,911:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,961:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,961:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,961:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,994:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,994:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:20,994:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,002:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,002:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,010:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,018:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,043:INFO:Calculating mean and std
2024-09-18 22:04:21,044:INFO:Creating metrics dataframe
2024-09-18 22:04:21,044:INFO:Uploading results into container
2024-09-18 22:04:21,044:INFO:Uploading model into container now
2024-09-18 22:04:21,044:INFO:_master_model_container: 4
2024-09-18 22:04:21,044:INFO:_display_container: 2
2024-09-18 22:04:21,044:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-18 22:04:21,044:INFO:create_model() successfully completed......................................
2024-09-18 22:04:21,094:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:21,094:INFO:Creating metrics dataframe
2024-09-18 22:04:21,102:INFO:Initializing SVM - Linear Kernel
2024-09-18 22:04:21,102:INFO:Total runtime is 0.2506004214286804 minutes
2024-09-18 22:04:21,110:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:21,110:INFO:Initializing create_model()
2024-09-18 22:04:21,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:21,110:INFO:Checking exceptions
2024-09-18 22:04:21,110:INFO:Importing libraries
2024-09-18 22:04:21,110:INFO:Copying training dataset
2024-09-18 22:04:21,110:INFO:Defining folds
2024-09-18 22:04:21,110:INFO:Declaring metric variables
2024-09-18 22:04:21,118:INFO:Importing untrained model
2024-09-18 22:04:21,118:INFO:SVM - Linear Kernel Imported successfully
2024-09-18 22:04:21,126:INFO:Starting cross validation
2024-09-18 22:04:21,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:21,232:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,232:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,232:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,239:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,239:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,247:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,255:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,255:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,255:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,255:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,255:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,255:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,263:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,271:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,271:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,271:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,271:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,279:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,287:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,296:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,296:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,296:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,296:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:21,296:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,320:INFO:Calculating mean and std
2024-09-18 22:04:21,320:INFO:Creating metrics dataframe
2024-09-18 22:04:21,320:INFO:Uploading results into container
2024-09-18 22:04:21,320:INFO:Uploading model into container now
2024-09-18 22:04:21,320:INFO:_master_model_container: 5
2024-09-18 22:04:21,320:INFO:_display_container: 2
2024-09-18 22:04:21,320:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-18 22:04:21,320:INFO:create_model() successfully completed......................................
2024-09-18 22:04:21,377:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:21,377:INFO:Creating metrics dataframe
2024-09-18 22:04:21,377:INFO:Initializing Ridge Classifier
2024-09-18 22:04:21,377:INFO:Total runtime is 0.2551856915156046 minutes
2024-09-18 22:04:21,385:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:21,385:INFO:Initializing create_model()
2024-09-18 22:04:21,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:21,385:INFO:Checking exceptions
2024-09-18 22:04:21,385:INFO:Importing libraries
2024-09-18 22:04:21,385:INFO:Copying training dataset
2024-09-18 22:04:21,385:INFO:Defining folds
2024-09-18 22:04:21,385:INFO:Declaring metric variables
2024-09-18 22:04:21,385:INFO:Importing untrained model
2024-09-18 22:04:21,396:INFO:Ridge Classifier Imported successfully
2024-09-18 22:04:21,401:INFO:Starting cross validation
2024-09-18 22:04:21,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:21,466:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,466:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,475:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,475:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,498:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,498:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,498:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,498:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,507:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,515:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,539:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,539:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,539:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,547:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,571:INFO:Calculating mean and std
2024-09-18 22:04:21,571:INFO:Creating metrics dataframe
2024-09-18 22:04:21,571:INFO:Uploading results into container
2024-09-18 22:04:21,571:INFO:Uploading model into container now
2024-09-18 22:04:21,571:INFO:_master_model_container: 6
2024-09-18 22:04:21,571:INFO:_display_container: 2
2024-09-18 22:04:21,571:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-18 22:04:21,571:INFO:create_model() successfully completed......................................
2024-09-18 22:04:21,627:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:21,627:INFO:Creating metrics dataframe
2024-09-18 22:04:21,635:INFO:Initializing Random Forest Classifier
2024-09-18 22:04:21,635:INFO:Total runtime is 0.25948661168416337 minutes
2024-09-18 22:04:21,643:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:21,643:INFO:Initializing create_model()
2024-09-18 22:04:21,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:21,643:INFO:Checking exceptions
2024-09-18 22:04:21,643:INFO:Importing libraries
2024-09-18 22:04:21,643:INFO:Copying training dataset
2024-09-18 22:04:21,643:INFO:Defining folds
2024-09-18 22:04:21,643:INFO:Declaring metric variables
2024-09-18 22:04:21,643:INFO:Importing untrained model
2024-09-18 22:04:21,651:INFO:Random Forest Classifier Imported successfully
2024-09-18 22:04:21,651:INFO:Starting cross validation
2024-09-18 22:04:21,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:21,995:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:21,995:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,003:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,003:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,003:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,003:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,003:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,003:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,011:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,011:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,011:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,011:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,019:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,019:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,019:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,019:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,027:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,035:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,035:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,035:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,035:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,044:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,052:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,052:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,052:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,068:INFO:Calculating mean and std
2024-09-18 22:04:22,068:INFO:Creating metrics dataframe
2024-09-18 22:04:22,068:INFO:Uploading results into container
2024-09-18 22:04:22,068:INFO:Uploading model into container now
2024-09-18 22:04:22,068:INFO:_master_model_container: 7
2024-09-18 22:04:22,068:INFO:_display_container: 2
2024-09-18 22:04:22,068:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-18 22:04:22,068:INFO:create_model() successfully completed......................................
2024-09-18 22:04:22,128:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:22,128:INFO:Creating metrics dataframe
2024-09-18 22:04:22,136:INFO:Initializing Quadratic Discriminant Analysis
2024-09-18 22:04:22,136:INFO:Total runtime is 0.2678312102953593 minutes
2024-09-18 22:04:22,136:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:22,136:INFO:Initializing create_model()
2024-09-18 22:04:22,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:22,136:INFO:Checking exceptions
2024-09-18 22:04:22,136:INFO:Importing libraries
2024-09-18 22:04:22,136:INFO:Copying training dataset
2024-09-18 22:04:22,144:INFO:Defining folds
2024-09-18 22:04:22,144:INFO:Declaring metric variables
2024-09-18 22:04:22,144:INFO:Importing untrained model
2024-09-18 22:04:22,144:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-18 22:04:22,152:INFO:Starting cross validation
2024-09-18 22:04:22,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:22,222:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,230:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,238:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,246:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,254:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,262:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,270:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,278:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,278:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,278:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,278:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,278:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,278:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,286:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,294:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,310:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,318:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,318:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,318:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,318:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,318:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,318:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,327:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-09-18 22:04:22,335:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,344:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,344:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:22,344:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,360:INFO:Calculating mean and std
2024-09-18 22:04:22,360:INFO:Creating metrics dataframe
2024-09-18 22:04:22,360:INFO:Uploading results into container
2024-09-18 22:04:22,360:INFO:Uploading model into container now
2024-09-18 22:04:22,360:INFO:_master_model_container: 8
2024-09-18 22:04:22,360:INFO:_display_container: 2
2024-09-18 22:04:22,360:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-18 22:04:22,360:INFO:create_model() successfully completed......................................
2024-09-18 22:04:22,418:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:22,418:INFO:Creating metrics dataframe
2024-09-18 22:04:22,427:INFO:Initializing Ada Boost Classifier
2024-09-18 22:04:22,435:INFO:Total runtime is 0.27268640597661337 minutes
2024-09-18 22:04:22,435:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:22,435:INFO:Initializing create_model()
2024-09-18 22:04:22,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:22,443:INFO:Checking exceptions
2024-09-18 22:04:22,443:INFO:Importing libraries
2024-09-18 22:04:22,443:INFO:Copying training dataset
2024-09-18 22:04:22,443:INFO:Defining folds
2024-09-18 22:04:22,443:INFO:Declaring metric variables
2024-09-18 22:04:22,451:INFO:Importing untrained model
2024-09-18 22:04:22,451:INFO:Ada Boost Classifier Imported successfully
2024-09-18 22:04:22,483:INFO:Starting cross validation
2024-09-18 22:04:22,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:22,555:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-18 22:04:22,648:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

 been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,649:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,649:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-18 22:04:22,649:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-18 22:04:22,649:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,657:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,761:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,761:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,769:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,769:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,777:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,777:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,777:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,777:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,785:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,794:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,810:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,819:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:22,819:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,819:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,819:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:22,835:INFO:Calculating mean and std
2024-09-18 22:04:22,835:INFO:Creating metrics dataframe
2024-09-18 22:04:22,835:INFO:Uploading results into container
2024-09-18 22:04:22,835:INFO:Uploading model into container now
2024-09-18 22:04:22,835:INFO:_master_model_container: 9
2024-09-18 22:04:22,835:INFO:_display_container: 2
2024-09-18 22:04:22,835:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-18 22:04:22,835:INFO:create_model() successfully completed......................................
2024-09-18 22:04:22,899:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:22,899:INFO:Creating metrics dataframe
2024-09-18 22:04:22,899:INFO:Initializing Gradient Boosting Classifier
2024-09-18 22:04:22,899:INFO:Total runtime is 0.2805512070655823 minutes
2024-09-18 22:04:22,907:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:22,907:INFO:Initializing create_model()
2024-09-18 22:04:22,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:22,907:INFO:Checking exceptions
2024-09-18 22:04:22,907:INFO:Importing libraries
2024-09-18 22:04:22,907:INFO:Copying training dataset
2024-09-18 22:04:22,907:INFO:Defining folds
2024-09-18 22:04:22,907:INFO:Declaring metric variables
2024-09-18 22:04:22,915:INFO:Importing untrained model
2024-09-18 22:04:22,923:INFO:Gradient Boosting Classifier Imported successfully
2024-09-18 22:04:22,943:INFO:Starting cross validation
2024-09-18 22:04:22,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:23,338:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,338:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,338:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,346:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,356:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,356:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,356:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,361:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,373:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,373:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,379:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,382:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,392:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,392:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,392:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,400:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,419:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,419:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,419:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,419:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,429:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,437:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,444:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,471:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,471:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,471:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,479:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,523:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,531:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,544:INFO:Calculating mean and std
2024-09-18 22:04:23,544:INFO:Creating metrics dataframe
2024-09-18 22:04:23,544:INFO:Uploading results into container
2024-09-18 22:04:23,544:INFO:Uploading model into container now
2024-09-18 22:04:23,552:INFO:_master_model_container: 10
2024-09-18 22:04:23,552:INFO:_display_container: 2
2024-09-18 22:04:23,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-18 22:04:23,552:INFO:create_model() successfully completed......................................
2024-09-18 22:04:23,616:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:23,616:INFO:Creating metrics dataframe
2024-09-18 22:04:23,624:INFO:Initializing Linear Discriminant Analysis
2024-09-18 22:04:23,624:INFO:Total runtime is 0.29263601700464886 minutes
2024-09-18 22:04:23,632:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:23,632:INFO:Initializing create_model()
2024-09-18 22:04:23,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:23,632:INFO:Checking exceptions
2024-09-18 22:04:23,632:INFO:Importing libraries
2024-09-18 22:04:23,632:INFO:Copying training dataset
2024-09-18 22:04:23,632:INFO:Defining folds
2024-09-18 22:04:23,632:INFO:Declaring metric variables
2024-09-18 22:04:23,640:INFO:Importing untrained model
2024-09-18 22:04:23,640:INFO:Linear Discriminant Analysis Imported successfully
2024-09-18 22:04:23,648:INFO:Starting cross validation
2024-09-18 22:04:23,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,744:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,752:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,760:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,764:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,764:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,764:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,764:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,772:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,772:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,772:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,772:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,780:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,788:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,789:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,790:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,791:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,797:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-18 22:04:23,798:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,798:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,798:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:23,822:INFO:Calculating mean and std
2024-09-18 22:04:23,822:INFO:Creating metrics dataframe
2024-09-18 22:04:23,822:INFO:Uploading results into container
2024-09-18 22:04:23,822:INFO:Uploading model into container now
2024-09-18 22:04:23,822:INFO:_master_model_container: 11
2024-09-18 22:04:23,822:INFO:_display_container: 2
2024-09-18 22:04:23,822:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-18 22:04:23,822:INFO:create_model() successfully completed......................................
2024-09-18 22:04:23,878:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:23,878:INFO:Creating metrics dataframe
2024-09-18 22:04:23,886:INFO:Initializing Extra Trees Classifier
2024-09-18 22:04:23,886:INFO:Total runtime is 0.29700090090433756 minutes
2024-09-18 22:04:23,894:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:23,894:INFO:Initializing create_model()
2024-09-18 22:04:23,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:23,894:INFO:Checking exceptions
2024-09-18 22:04:23,894:INFO:Importing libraries
2024-09-18 22:04:23,894:INFO:Copying training dataset
2024-09-18 22:04:23,894:INFO:Defining folds
2024-09-18 22:04:23,894:INFO:Declaring metric variables
2024-09-18 22:04:23,902:INFO:Importing untrained model
2024-09-18 22:04:23,902:INFO:Extra Trees Classifier Imported successfully
2024-09-18 22:04:23,918:INFO:Starting cross validation
2024-09-18 22:04:23,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:24,227:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,227:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,235:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,235:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,235:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,235:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,235:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,244:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,244:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,244:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,244:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,252:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,252:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,260:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,260:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,260:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,260:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,260:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,260:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,268:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,268:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,268:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,277:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,277:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,277:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,285:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,302:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,327:INFO:Calculating mean and std
2024-09-18 22:04:24,327:INFO:Creating metrics dataframe
2024-09-18 22:04:24,327:INFO:Uploading results into container
2024-09-18 22:04:24,327:INFO:Uploading model into container now
2024-09-18 22:04:24,327:INFO:_master_model_container: 12
2024-09-18 22:04:24,327:INFO:_display_container: 2
2024-09-18 22:04:24,327:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-18 22:04:24,327:INFO:create_model() successfully completed......................................
2024-09-18 22:04:24,385:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:24,385:INFO:Creating metrics dataframe
2024-09-18 22:04:24,393:INFO:Initializing Extreme Gradient Boosting
2024-09-18 22:04:24,393:INFO:Total runtime is 0.3054548780123393 minutes
2024-09-18 22:04:24,401:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:24,401:INFO:Initializing create_model()
2024-09-18 22:04:24,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:24,401:INFO:Checking exceptions
2024-09-18 22:04:24,401:INFO:Importing libraries
2024-09-18 22:04:24,401:INFO:Copying training dataset
2024-09-18 22:04:24,401:INFO:Defining folds
2024-09-18 22:04:24,401:INFO:Declaring metric variables
2024-09-18 22:04:24,401:INFO:Importing untrained model
2024-09-18 22:04:24,409:INFO:Extreme Gradient Boosting Imported successfully
2024-09-18 22:04:24,417:INFO:Starting cross validation
2024-09-18 22:04:24,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:24,695:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,695:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,695:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,703:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,703:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,703:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,703:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,703:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,711:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,711:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,711:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,711:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,711:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,711:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,719:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,727:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,727:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,727:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,727:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,727:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,735:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,743:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:24,752:INFO:Calculating mean and std
2024-09-18 22:04:24,752:INFO:Creating metrics dataframe
2024-09-18 22:04:24,752:INFO:Uploading results into container
2024-09-18 22:04:24,752:INFO:Uploading model into container now
2024-09-18 22:04:24,752:INFO:_master_model_container: 13
2024-09-18 22:04:24,752:INFO:_display_container: 2
2024-09-18 22:04:24,752:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-18 22:04:24,752:INFO:create_model() successfully completed......................................
2024-09-18 22:04:24,811:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:24,811:INFO:Creating metrics dataframe
2024-09-18 22:04:24,819:INFO:Initializing Light Gradient Boosting Machine
2024-09-18 22:04:24,819:INFO:Total runtime is 0.31254712343215946 minutes
2024-09-18 22:04:24,819:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:24,819:INFO:Initializing create_model()
2024-09-18 22:04:24,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:24,819:INFO:Checking exceptions
2024-09-18 22:04:24,819:INFO:Importing libraries
2024-09-18 22:04:24,819:INFO:Copying training dataset
2024-09-18 22:04:24,827:INFO:Defining folds
2024-09-18 22:04:24,827:INFO:Declaring metric variables
2024-09-18 22:04:24,827:INFO:Importing untrained model
2024-09-18 22:04:24,827:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-18 22:04:24,835:INFO:Starting cross validation
2024-09-18 22:04:24,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:25,678:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,678:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,686:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,718:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,728:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,728:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,745:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,745:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,753:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,795:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,795:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,795:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,827:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,827:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,835:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,852:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,854:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,854:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,896:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,896:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,896:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,904:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,904:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,912:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,920:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,920:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,928:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,944:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,944:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,952:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:25,968:INFO:Calculating mean and std
2024-09-18 22:04:25,970:INFO:Creating metrics dataframe
2024-09-18 22:04:25,970:INFO:Uploading results into container
2024-09-18 22:04:25,970:INFO:Uploading model into container now
2024-09-18 22:04:25,970:INFO:_master_model_container: 14
2024-09-18 22:04:25,970:INFO:_display_container: 2
2024-09-18 22:04:25,970:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-18 22:04:25,970:INFO:create_model() successfully completed......................................
2024-09-18 22:04:26,045:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:26,045:INFO:Creating metrics dataframe
2024-09-18 22:04:26,058:INFO:Initializing Dummy Classifier
2024-09-18 22:04:26,058:INFO:Total runtime is 0.3331972201665243 minutes
2024-09-18 22:04:26,066:INFO:SubProcess create_model() called ==================================
2024-09-18 22:04:26,066:INFO:Initializing create_model()
2024-09-18 22:04:26,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020BC3DBD990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:26,066:INFO:Checking exceptions
2024-09-18 22:04:26,066:INFO:Importing libraries
2024-09-18 22:04:26,066:INFO:Copying training dataset
2024-09-18 22:04:26,068:INFO:Defining folds
2024-09-18 22:04:26,068:INFO:Declaring metric variables
2024-09-18 22:04:26,068:INFO:Importing untrained model
2024-09-18 22:04:26,077:INFO:Dummy Classifier Imported successfully
2024-09-18 22:04:26,085:INFO:Starting cross validation
2024-09-18 22:04:26,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-18 22:04:26,149:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,157:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,165:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,165:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,165:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,173:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,181:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,181:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,181:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,181:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,189:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,197:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,205:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,213:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,213:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-18 22:04:26,213:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Gentoo') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-09-18 22:04:26,221:INFO:Calculating mean and std
2024-09-18 22:04:26,221:INFO:Creating metrics dataframe
2024-09-18 22:04:26,221:INFO:Uploading results into container
2024-09-18 22:04:26,221:INFO:Uploading model into container now
2024-09-18 22:04:26,221:INFO:_master_model_container: 15
2024-09-18 22:04:26,221:INFO:_display_container: 2
2024-09-18 22:04:26,221:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-18 22:04:26,221:INFO:create_model() successfully completed......................................
2024-09-18 22:04:26,285:INFO:SubProcess create_model() end ==================================
2024-09-18 22:04:26,285:INFO:Creating metrics dataframe
2024-09-18 22:04:26,298:WARNING:d:\Inferencing\practice_penguins\env_penguins\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-18 22:04:26,306:INFO:Initializing create_model()
2024-09-18 22:04:26,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-18 22:04:26,306:INFO:Checking exceptions
2024-09-18 22:04:26,306:INFO:Importing libraries
2024-09-18 22:04:26,306:INFO:Copying training dataset
2024-09-18 22:04:26,306:INFO:Defining folds
2024-09-18 22:04:26,314:INFO:Declaring metric variables
2024-09-18 22:04:26,314:INFO:Importing untrained model
2024-09-18 22:04:26,314:INFO:Declaring custom model
2024-09-18 22:04:26,314:INFO:Random Forest Classifier Imported successfully
2024-09-18 22:04:26,314:INFO:Cross validation set to False
2024-09-18 22:04:26,314:INFO:Fitting Model
2024-09-18 22:04:26,469:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-18 22:04:26,469:INFO:create_model() successfully completed......................................
2024-09-18 22:04:26,551:INFO:_master_model_container: 15
2024-09-18 22:04:26,551:INFO:_display_container: 2
2024-09-18 22:04:26,551:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-18 22:04:26,551:INFO:compare_models() successfully completed......................................
2024-09-18 22:04:30,478:INFO:Initializing save_model()
2024-09-18 22:04:30,478:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), model_name=./model/penguins-best, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\10188\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['culmen_length_mm',
                                             'culmen_depth_mm',
                                             'flipper_length_mm',
                                             'body_mass_g'],
                                    transformer=SimpleImputer(ad...
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': FEMALE    0
MALE      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['island'],
                                    transformer=OneHotEncoder(cols=['island'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-09-18 22:04:30,478:INFO:Adding model into prep_pipe
2024-09-18 22:04:30,611:INFO:./model/penguins-best.pkl saved in current working directory
2024-09-18 22:04:30,652:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['culmen_length_mm',
                                             'culmen_depth_mm',
                                             'flipper_length_mm',
                                             'body_mass_g'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-09-18 22:04:30,652:INFO:save_model() successfully completed......................................
2024-09-18 22:04:33,243:INFO:Initializing predict_model()
2024-09-18 22:04:33,243:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020BC45CBF70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020B806891B0>)
2024-09-18 22:04:33,243:INFO:Checking exceptions
2024-09-18 22:04:33,243:INFO:Preloading libraries
2024-09-18 22:04:33,243:INFO:Set up data.
2024-09-18 22:04:33,251:INFO:Set up index.
2024-09-18 22:04:48,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:48,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:48,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:48,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-18 22:04:53,687:INFO:Initializing load_model()
2024-09-18 22:04:53,687:INFO:load_model(model_name=./model/penguins-best, platform=None, authentication=None, verbose=True)
2024-09-18 22:05:01,620:INFO:Initializing load_model()
2024-09-18 22:05:01,620:INFO:load_model(model_name=./model/penguins-best, platform=None, authentication=None, verbose=True)
2024-09-18 22:05:03,286:INFO:Initializing predict_model()
2024-09-18 22:05:03,286:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001727F729360>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['culmen_length_mm',
                                             'culmen_depth_mm',
                                             'flipper_length_mm',
                                             'body_mass_g'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['island', 'sex'],
                                    transforme...
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': FEMALE    0
MALE      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['island'],
                                    transformer=OneHotEncoder(cols=['island'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001727FA920E0>)
2024-09-18 22:05:03,286:INFO:Checking exceptions
2024-09-18 22:05:03,286:INFO:Preloading libraries
2024-09-18 22:05:03,286:INFO:Set up data.
2024-09-18 22:05:03,286:INFO:Set up index.
